# In model_experimentation.ipynb

# 1. Imports and Data Loading
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
# ... import other models you want to try ...
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score # ... other metrics

import matplotlib.pyplot as plt
import seaborn as sns


# Ensure path is set correctly
import os
from pathlib import Path
DATA_DIR = "data"
PROCESSED_DATA_DIR = os.path.join(Path().resolve().parent, os.path.join(DATA_DIR, "processed"))
combined_data = pd.read_csv(os.path.join(PROCESSED_DATA_DIR, "combined_data.csv"))



# ... (Load your combined_data.csv as in previous examples)

# Drop unnecessary columns
data_for_model = combined_data.drop(columns=['composer', 'date_created', 'date_recorded','information','language_code','license','lyricist','publisher','tags','title'])
combined_data = pd.get_dummies(data_for_model, columns=['genres','genres_all'], dummy_na=False)

# 2. Feature Engineering (if needed, add after data exploration in the same notebook)

# ... (Any new features you create based on EDA should be added here)


# 3. Data Splitting
X = combined_data.drop(columns=['genre_top', 'track_id'])  # Drop the target
y = combined_data['genre_top']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

# 4. Model Experimentation

# Example 1: Logistic Regression with Scaler
numerical_features = X_train.select_dtypes(include=np.number).columns.tolist()
categorical_features = X_train.select_dtypes(include=['object', 'category']).columns.tolist()


numeric_transformer = Pipeline([('scaler', StandardScaler())])
categorical_transformer = Pipeline([('onehot', OneHotEncoder(handle_unknown='ignore'))])
preprocessor = ColumnTransformer([
    ('num', numeric_transformer, numerical_features),
    ('cat', categorical_transformer, categorical_features)])

model = Pipeline([
    ('preprocessor', preprocessor),
    ('classifier', LogisticRegression(solver='liblinear', multi_class='ovr'))  # solver and multi_class for multinomial
])

cv_scores = cross_val_score(model, X_train, y_train, cv=5)  # Example: 5-fold cross-validation

print(f"Logistic Regression CV scores: {cv_scores}")
print(f"Logistic Regression Mean CV score: {np.mean(cv_scores)}")


# Example 2: Random Forest with Hyperparameter Tuning
model = Pipeline([
    ('preprocessor', preprocessor),
    ('classifier', RandomForestClassifier(random_state=42))
])

param_grid = {
    'classifier__n_estimators': [50, 100, 200],
    'classifier__max_depth': [None, 10, 20]
}

grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy')  # scoring= accuracy for tuning
grid_search.fit(X_train, y_train)

print(f"RandomForest Best parameters: {grid_search.best_params_}")
print(f"RandomForest Best score: {grid_search.best_score_}")


# Example 3: Gradient Boosting

# ... (add other models and experiments, compare performance, etc.)


# 5. Model Evaluation (On the best performing model)
best_model = grid_search.best_estimator_ # Assuming RandomForest was the best after experimentation
y_pred = best_model.predict(X_test)


print(classification_report(y_test, y_pred))

cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=best_model.classes_, yticklabels=best_model.classes_)
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.xticks(rotation=45)  # Rotate x-axis labels for better readability
plt.yticks(rotation=0) # Keep y-axis labels vertical
plt.tight_layout()
plt.show()